{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will explore and analyze data from NYC Taxi and Limousine Commission (TLC) in June 2018. We then build a predictive model for whether a trip will be tipped or not, which is a classification problem. By interpreting the feature importances, we will see what types of trips are more likely to be tipped. \n",
    "\n",
    "Data is downloaded from https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page (2018 June Green)\n",
    "\n",
    "The green taxi trip records include fields capturing pick-up and drop-off dates/times, pick-up and drop-off locations, trip distances, itemized fares, rate types, payment types, and driver-reported passenger counts. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None) # this will show all the columns in dataframe\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, r2_score, mean_squared_error\n",
    "\n",
    "import time\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please create a folder named \"data\"\n",
    "# all data should be put into \"data\" folder\n",
    "file_name = 'green_tripdata_2018-06.csv'\n",
    "file_path = '../data/'\n",
    "\n",
    "trips = pd.read_csv(file_path + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* VendorID: LPEP provider that provided the data record (1 = Creative Mobile Technologies, LLC; 2=VeriFone Inc.)\n",
    "* lpep_pickup_datetime: The time when meter was engaged\n",
    "* lpep_dropoff_datetime: The time when meter was disengaged\n",
    "* store_and_fwd_flag: This flag indicates whether the trip record was held in vehicle memory before sending to the vendor, aka “store and forward,” because the vehicle did not have a connection to the server\n",
    "* RatecodeID: The final rate code in effect at the end of the trip.\n",
    "* PULocationID: TLC taxi zone for pickup\n",
    "* DOLocationID: TLC taxi zone for dropoff\n",
    "* passenger_count: The number of passengers in the vehicle. Recorded by driver\n",
    "* trip_distance: trip distance in miles\n",
    "* fare_amount: The time-and-distance fare calculated by the meter\n",
    "* extra: the 0.50 and 1 rush hour, and overnight charges\n",
    "* mta_tax: 0.50 MTA tax that is automatically triggered based on the metered rate in use\n",
    "* tip_amount: This field is automatically populated for credit card tips. **Cash tips are not included**\n",
    "* tolls_amount: Total amount of all tolls paid in trip\n",
    "* ehail_fee: NULL\n",
    "* improvement_surcharge: 0.30 improvement surcharge assessed on hailed trips at the flag drop. The improvement surcharge began being levied in 2015\n",
    "* total_amount: The total amount charged to passengers. **Does not include cash tips**\n",
    "* payment_type: how the passenger paid for the trip\n",
    "* trip_type: A code indicating whether the trip was a street-hail or a dispatch that is automatically assigned based on the metered rate in use but can be altered by the driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above description, we find an interesting thing that might affect the prediction of tips. We do not have cash tips information in the dataset. To make it closer to the Uber situation, we choose *credit card* as the payment type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_cc = trips[trips['payment_type']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report rows and columns\n",
    "print ('Number of samples: ', trips_cc.shape[0])\n",
    "print ('Number of features: ', trips_cc.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we derive a new variable, **is_tipped**, which is whether the trip is tipped. In order to get this new variable, we can refer to \"tip amount\". \n",
    "\n",
    "Before creating **is_tipped** variable, we should look at *total amount* and *tip amount* to get some insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_cc['total_amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of samples with total amount less than 3\n",
    "sum(trips_cc['total_amount']<=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the minimum total amount (extras and surcharges), we believe the records with total amount less than 3 are considered outliers. The quantity of these outliers is small (256 out of 417076), so it is better to remove them.\n",
    "\n",
    "For the maximum value of 485, it is considered reasonable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_cc = trips_cc[trips_cc['total_amount']>3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the distribution of total amount\n",
    "trips_cc['total_amount'].hist(bins=100)\n",
    "plt.xlabel(\"total amount\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tip Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_cc['tip_amount'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution seems good. No need to process tip amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## is_tipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new feature, named is_tipped\n",
    "trips_cc['is_tipped'] = trips_cc['tip_amount'].apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot\n",
    "x_pos = ['Tip','No Tip']\n",
    "x = trips_cc['is_tipped'].value_counts()\n",
    "\n",
    "plt.bar(x_pos, x, color='green')\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.title(\"Bar plot of whether the trip is tipped\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the data is somehow balanced. Even though, we should still use both accuracy and AUC as evaluation metrics. Besides, we should monitor the running time to see which algorithm runs fast and which is very slow to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = trips_cc.select_dtypes(include = [np.number]).corr()\n",
    "\n",
    "print(correlation['tip_amount'].sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might wonder if tip amount has a high correlation with total amount minus fare amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove nan\n",
    "df = correlation[['tip_amount', 'total_amount', 'fare_amount']].dropna()\n",
    "\n",
    "# coefficient\n",
    "np.corrcoef(df['tip_amount'], df['total_amount'] - df['fare_amount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total amount should not be included in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at relationship between fare_amount and the target has_tip\n",
    "trips_cc.boxplot(column='fare_amount', by='is_tipped')\n",
    "plt.ylim(0,100)\n",
    "plt.ylabel(\"total amount\")\n",
    "plt.title(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data For Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we prepare data for classification and regression model. First we clean data by removing irrelevant features, checking missing values. Then we use pickup and dropoff time to create some new features that might be useful. Before modeling, we also introduce some feature selection techniques. However, the number of features in this dataset is not too large, so feature selection might not be significantly important. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_cc.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is actually pretty clean, with no missing value except feature 'ehail_fee', which contains all missing value and should be removed. The dataset is clean because we only choose \"credit card\" payment type. Some other missing values may occur at other payment type.\n",
    "\n",
    "Besides, VendorID is id-like variable and should also be removed. Since we already choose credit card, payment_type can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "\n",
    "# ehail_fee: drop the column\n",
    "trips_cc.drop(['ehail_fee', 'VendorID', 'payment_type'],axis=1, inplace=True)\n",
    "\n",
    "print ('Done with data cleaning!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Feature Engineering, we create several new features, including day of month, weekday, hour from pickup datetime. We can also generate trip duration and trip speed, which are easy to get from original features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert lpep pickup datetime to standard datetime format\n",
    "trips_cc['pickup_datetime'] = trips_cc['lpep_pickup_datetime'].apply(\n",
    "    lambda x: datetime.strptime(x,'%Y-%m-%d %H:%M:%S'))\n",
    "# extract day of month\n",
    "trips_cc['monthday'] = trips_cc['pickup_datetime'].apply(lambda x: x.day)\n",
    "# get weekday\n",
    "trips_cc['weekday'] = trips_cc['pickup_datetime'].apply(lambda x: x.weekday() + 1)\n",
    "# get hour of day\n",
    "trips_cc['hour'] = trips_cc['pickup_datetime'].apply(lambda x: x.hour)\n",
    "\n",
    "# derive Trip duration\n",
    "trips_cc['dropoff_datetime'] = trips_cc['lpep_dropoff_datetime'].apply(\n",
    "    lambda x: datetime.strptime(x,'%Y-%m-%d %H:%M:%S'))\n",
    "trips_cc['trip_duration'] = (trips_cc['dropoff_datetime'] - trips_cc['pickup_datetime']) / np.timedelta64(1, 'm')\n",
    "\n",
    "# remove duration less than 0\n",
    "trips_cc = trips_cc[trips_cc['trip_duration'] > 0]\n",
    "\n",
    "# derive Trip speed with miles per hour\n",
    "trips_cc['trip_speed'] = trips_cc['trip_distance'] / (trips_cc['trip_duration'] / 60.0)\n",
    "\n",
    "# remove speed greater than 80\n",
    "trips_cc = trips_cc[trips_cc['trip_speed'] <= 80]\n",
    "\n",
    "print ('Done with feature engineering!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mta_tax and improvement_surcharge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By analyzing mta_tax and improvement_surcharge, we see the imbalance of the values, indicating that these two features may not contribute much to the predictive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (trips_cc['mta_tax'].value_counts())\n",
    "\n",
    "print (trips_cc['improvement_surcharge'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### passenger_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (trips_cc['passenger_count'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is impossible to have 0 passenger. To make it simple, remove those samples\n",
    "* 7/8/9 can be merged to 6.\n",
    "* Even though it is passenger count, we should regard it as a categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 0 passenger\n",
    "trips_cc = trips_cc[trips_cc['passenger_count'] != 0]\n",
    "\n",
    "# merge 7/8/9 to 6 \n",
    "trips_cc['passenger_count'] = trips_cc['passenger_count'].apply(lambda x: 6 if x >= 6 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Irrelevant Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datetime-related features are irrelevant. It makes no sense to add those variables to model. In addition, we have already extract some useful information from them. Thus we can remove them.\n",
    "\n",
    "Store_and_fwd_flag feature indicates whether the trip record was held in vehicle memory before sending to the vendor. This might differ because the vehicle did not have a connection to the server, which has no relationship with tip. We can also remove it.\n",
    "\n",
    "At last, tip amount and total amount should be removed, since it is response-related variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_cc.drop(['lpep_pickup_datetime',\n",
    "               'lpep_dropoff_datetime',\n",
    "               'pickup_datetime',\n",
    "               'dropoff_datetime',\n",
    "               'store_and_fwd_flag',\n",
    "               'tip_amount', 'total_amount'],axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_cc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there are too many features and it is impossible to handle them manually, one way to solve the problem is to perform feature selection. Even though some models contain this technique (LASSO), which is called embeded feature  seletion, here we introduce filter method using two measure, Chi-square and F-score. \n",
    "\n",
    "Please note that, in this dataset, the number of features is not large. Thus, feature selection might not increase the model performance, especially for some complicated models such as Random Forest and Boosting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2, f_classif \n",
    "\n",
    "def selectFeatures(method, X, y, features):\n",
    "    \"\"\"\n",
    "    Supervised feature selection. Chi2 and Mutual Information are supported\n",
    "\n",
    "    Args:\n",
    "        method: str, one of \"chi2\" and \"f\"\n",
    "        X: numpy array, sparse matrix or pandas dataframe\n",
    "        y: target variable\n",
    "        features: names of feature to be selected\n",
    "\n",
    "    Return:\n",
    "        Sorted list of features by their scores\n",
    "    \"\"\"\n",
    "    # method check\n",
    "    if method not in [\"chi2\", \"f\"]:\n",
    "        raise Exception(\"Only Chi2 and f score are supported.\")\n",
    "    if method == \"chi2\":\n",
    "        score, _ = chi2(X, y)\n",
    "    elif method == \"f\":\n",
    "        score, _ = f_classif(X, y)\n",
    "    score = np.nan_to_num(score)\n",
    "    return sorted(zip(*(features, score)), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in trips_cc.columns if x not in ['is_tip']]\n",
    "X = trips_cc[features].values\n",
    "y = trips_cc['is_tipped'].values\n",
    "\n",
    "chi2 = selectFeatures('chi2', X, y, features)\n",
    "f = selectFeatures('f', X, y, features)\n",
    "\n",
    "chi2_df = pd.DataFrame(chi2, columns=['feature','chi2'])\n",
    "f_df = pd.DataFrame(f, columns=['feature','f_score'])\n",
    "merged_df = chi2_df.merge(f_df,on='feature',how='inner')\n",
    "\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_cc.drop([\"passenger_count\", \"trip_speed\", \"trip_type\", \"mta_tax\", \"improvement_surcharge\"],\n",
    "              axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both of the feature selection methods, variables \"passenger_count\", \"trip_speed\", \"trip_type\", \"mta_tax\", \"improvement_surcharge\" have relatively low scores and I just remove them. \n",
    "\n",
    "Now we are ready for the modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step of the prediction process is to perform the classification model. The output variable is \"is_tipped\", with 1 tip and 0 no tip. \n",
    "\n",
    "Before applying models, we should divide dataset into two parts, the training set and test set. We use training set to train models, select models and tune hyperparameters. We never use test set until the classification and regression models are completed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get predictors\n",
    "predictors = [x for x in trips_cc.columns if x not in ['is_tipped']]\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(trips_cc[predictors].values, trips_cc['is_tipped'].values, \n",
    "                                              test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Roughly train Logistic Regression, Decision Tree, Bagging, SVM, Random Forest, AdaBoost and GBDT\n",
    "* Choose a best model to tune hyperparameters using cross validation. If multiple models have similar performance, tune both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model selection using cross validation \n",
    "def cross_validation(X, y, cv, classifier,**kwargs):\n",
    "    \"\"\"\n",
    "    @input\n",
    "        X:          feature space \n",
    "        y:          label\n",
    "        classifier: classification model\n",
    "        cv:         num of folds   \n",
    "        **kwargs:   parameters in classifier\n",
    "    @output:\n",
    "        y_predict\n",
    "    \"\"\" \n",
    "    start = time.time()\n",
    "    kf = KFold(n_splits=cv,shuffle=True)\n",
    "    y_predict = y.copy()\n",
    "    clf = classifier(**kwargs)\n",
    "    \n",
    "    accuracy = 0\n",
    "    auc = 0\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_predict = clf.predict(X_test)\n",
    "        accuracy += np.mean(y_predict==y_test)\n",
    "        auc += roc_auc_score(y_test, y_predict)\n",
    "    \n",
    "    end = time.time()\n",
    "    return accuracy/cv, auc/cv, end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run classification model\n",
    "\n",
    "# potential models\n",
    "models = [LogisticRegression, DecisionTreeClassifier, \n",
    "          BaggingClassifier, RandomForestClassifier, \n",
    "          AdaBoostClassifier, GradientBoostingClassifier]\n",
    "\n",
    "# results\n",
    "res_dict = {}\n",
    "\n",
    "# train models\n",
    "for model in models:\n",
    "    print (\"Training model: \", model)\n",
    "    tmp_acc, tmp_auc, tmp_runtime = cross_validation(X_train, y_train, 5, model)\n",
    "    res_dict[model] = [tmp_acc, tmp_auc, tmp_runtime]\n",
    "\n",
    "print ('Done with classification model selection!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(res_dict).T\n",
    "res_df.columns = [\"Accuracy\",\"AUC\",\"RunTime\"]\n",
    "\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance result is from the 5-fold Cross Validation. Even though Bagging performed the best, I would like to choose **Random Forest** as my classification model for two reasons.\n",
    "\n",
    "* Random Forest is much faster.\n",
    "* Random Forest supports feature importance.\n",
    "\n",
    "Then we could use RandomSearch to automatically tune hyperparameters.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "In sklearn, there are several hyperparameters to tune in Random Forest.\n",
    "\n",
    "* n_estimators: The number of base estimators in the ensemble\n",
    "* max_depth: The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "* min_samples_split: The minimum number of samples required to split an internal node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "RF_params = {\n",
    "    'n_estimators': [10,50,100],\n",
    "    'max_depth': [5,20,None],\n",
    "    'min_samples_split': [2,5,10]\n",
    "                 }\n",
    "start = time.time()\n",
    "\n",
    "rs_RF = RandomizedSearchCV(\n",
    "    RandomForestClassifier(), # classifier\n",
    "    RF_params, # your parameter distribution\n",
    "    n_iter = 20, # number of candidates among total that you will randomly search for\n",
    "    scoring = \"roc_auc\", # evaluation metrics\n",
    "    cv=5, # number of folds\n",
    "    verbose=True)\n",
    "\n",
    "rs_RF.fit(X_train, y_train)\n",
    "\n",
    "print (\"RandomizedSearchCV took %.2f seconds for Random Forest\"%(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the results\n",
    "rs_RF.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the optimal parameters\n",
    "rs_RF.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best AUC \n",
    "rs_RF.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the best parameters to train\n",
    "RF_best = RandomForestClassifier(n_estimators=100, min_samples_split=5, max_depth=None)\n",
    "RF_best.fit(X_train, y_train)\n",
    "y_pred_train = RF_best.predict(X_train)\n",
    "y_pred = RF_best.predict(X_test)\n",
    "\n",
    "print (\"AUC on training set: \", roc_auc_score(y_train, y_pred_train))\n",
    "print (\"AUC on test set: \", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show feature importances\n",
    "feature_importance = pd.DataFrame(predictors, columns=['feature'])\n",
    "feature_importance['importance'] = RF_best.feature_importances_\n",
    "feature_importance.plot(x='feature',y='importance',xticks=range(len(predictors)),rot=60,figsize=(8,4))\n",
    "plt.ylabel('feature importance')\n",
    "plt.title(\"Figure 14: The importance values of features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 7 classification models to fit green taxi data, in order to classify if a trip will be tipped or not. During model selection, Bagging, Random Forest and Gradient Boosting performed better, which is reasonable. Logistic Regression or Decision Tree seems too simple for this data, and somehow underfitting. \n",
    "\n",
    "Even though Bagging performed the best, we choose Random Forest as the final model for two reasons. First, Random Forest run twice as fast as Bagging. Second, feature importance can be generated in Random Forest, while Bagging does not support this function. \n",
    "\n",
    "By tunning Random Forest, we get **{'n_estimators': 100, 'min_samples_split': 5, 'max_depth': None}** as the best parameters, using Random Search Cross Validation. We then train the whole training set using these hyperparameters and test on test set. \n",
    "\n",
    "* AUC 0.96 on training set\n",
    "* AUC 0.76 on test set\n",
    "\n",
    "The result shows overfitting. Even though we tried several parameters that might lead to underfitting, it still shows overfitting. The problem may come from the dataset. \n",
    "\n",
    "* Internally, the split might differ a lot\n",
    "* Externally, we can set a higher proportion of test set\n",
    "\n",
    "In the end, we analyze the feature importance. Trip duration/distance and pickup/dropoff location stand out. This result makes sense. First, long trip might have more chance to be tipped, since passengers will feel that the driver is working hard and give some tips. Second, certain locations indicate certain kind of people, who are more likely to give tips. \n",
    "\n",
    "By using this information, drivers who are likely to be tipped can get the order with long distance, but it may take a longer time. Also, Uber or some other companies can use location information to get more drivers among those area. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "335.966px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
